[
  {
    "path": "projects/2021-07-13-retroactivelyReproducible/",
    "title": "Retroactively Reproducible: Lessons from a workflow audit",
    "description": "A talk I gave at the 2021 SORTEE conference about my experience implementing data management and reproducibility tools retroactively, for an existing project, even if best practices weren’t used from the beginning. I also discuss organizing and making sense of someone else’s analyses when approaching the project as an outsider.",
    "author": [
      {
        "name": "Kaija Gahm",
        "url": {}
      }
    ],
    "date": "2021-07-13",
    "categories": [],
    "contents": "\n\nContents\nSlides and descriptions\nVideo\nResources\n\n\n\n\nAt the 2021 SORTEE conference this past summer, I gave a talk about my experience conducting a reproducibility audit and cleaning up a colleague’s workflow as she prepared to publish her M.S. thesis research.\nHere, I’m embedding the video of the talk, and also reproducing it as a blog post (slides and captions) in case you’d rather read than listen/watch.\nThe slide descriptions are a pretty direct transcription of what I said during the talk, so if the style seems strange for a blog post, that’s why.\nScroll down to watch the video!\nSlides and descriptions\n\nHello everyone! Thank you for being here. My name is Kaija Gahm, and I’m a data manager at the Cary Institute of Ecosystem Studies. Late last year, my colleague Chelsea had just finished her Master’s thesis, and my supervisor asked me to help her to organize her code and analysis into a reproducible workflow that we could reference in the manuscript that we were putting together.  In this talk, I’m going to be speaking about my experience implementing data management and reproducibility tools retroactively, for an existing project, even if best practices weren’t used from the beginning. I’ll also discuss organizing and making sense of someone else’s analyses, approaching the project as an outsider.A little bit of background on the project: It consisted of some pretty typical ecological data––measurements of lake dissolved organic carbon, morphometric landmarks of bluegill sunfish, and a bunch of statistical analyses and figures.Some of the challenges I knew I was going to face were that the data had largely been edited manually in Excel, or copied and pasted from other files with uncertain origin.There were many file versions, and it wasn’t really clear how the data and code tied together.The goal of my work was to compile all of this data and code into a reproducible analysis. I knew that we were going to be storing the data on Figshare; all of the analyses would be conducted in RStudio and stored on GitHub. The data and code could be then referenced in the final manuscript.To begin my work, I asked Chelsea to start by uploading all of her files to GitHub.I think GitHub is a very important tool, not just technically, for version control, but also psychologically. If everything was being version controlled, then I would have the power to edit and delete without being burdened by the idea that I might be deleting something very important. I knew that as long as everything was on GitHub, I could always walk the repository back to its original version.My first step in organizing this repository was to set it up as an RStudio Project, which means that it would open a fresh R session for everyone who downloaded the code, and all file paths could be written relative to the root directory.  I also implemented renv, which is a great package that allows for managing package versions. This was particularly important in the case of this analysis, because some of the code depended on an old version of the geomorph package for analyzing morphometric landmarks. I personally wasn’t very familiar with the package, so even if I had wanted to update the code to the newest version, I wouldn’t really have been able to. Using renv allowed me to run the code with the old version of the package, and it ensures that anyone who wants to run our analysis in the future will be able to restore the packages from the lockfile and immediately proceed without affecting packages on their own computer.My next step was to organize the data.  The first principle is that raw data is sacred and should not be modified. So that means no copying and pasting. Derived data should then be fully reproducible and, by extension, disposable. I should be able to just delete all of the derived data, and then recreate it by re-running the scripts in the pipeline. Now, that might be a bit of a pain because some of the analyses might take a long time to run, but it would be possible in a fully reproducible analysis. And my job approaching this project was to distinguish between data that was raw––like maybe it was created manually or it was exported from a program somewhere else––versus data that could be regenerated from the analysis code.This is a list of all the data files that I was originally presented with in the GitHub repository, and it was pretty overwhelming. I had to sort through all of those and figure out which were raw, which were derived, and where they all went in the pipeline.And in order to do this, I asked the key question, ‘Where did this come from?’ For each file, I wanted to know, how was it generated? Can I trace the origin of all the files and their columns?I started out by making a spreadsheet listing out each file, and this seemed like a good idea at the time, but it ended up being pretty overwhelming, and it was hard for Chelsea to go through and answer my questions, especially because I was attacking all the files at once, without regard for their importance or the order that they might go in. I was just trying to get my head around it.Chelsea and I decided that a better approach would be to start with the most recent and up-to-date analysis file; in our case, called ReviewApril2020.Then, I could look at all of the data files that were read in as inputs. It was much easier, with this reduced set of files, to determine……which ones were raw data and which ones were derived data. So, my next step was, for each of those derived data files, to figure out how to re-create it from the data in the database, using R scripts, so that the process would be fully reproducible.To do that, I created one R script for each of the derived data files, and I used that R script to read in data from the database stored on Figshare and modify it to generate these ‘FINAL’ csv files. In the background, I kept the original data and used it as a comparison, just to make sure I was accurately recreating that original data.My next step was to organize the code in the analysis files. I had to start by reorganizing a lot of file paths; they had been written as absolute paths, and I rewrote them as relative paths using the wonderful here package.I clarified a lot of the code by renaming the variables with descriptive names and adding clear comments.I also organized the code to make sure it was easy to read and follow.And to do that, I made heavy use of the outline panel within RStudio, which you can access by clicking on this sort of list icon at the top right corner of the script pane. You’ll notice that this ‘Load packages’ header corresponds to a line in this document outline, and that actually happens automatically within RStudio.You can create these header lines by clicking Command + Shift + R on a Mac, and they automatically get added to the outlines. And then you can also see that I have a lot of packages loaded at the top here, a lot of comments, and everything is just a little bit cleaner and easier to read.I wrote a README to document this project, including an abstract to introduce people to the project, instructions for how to download the data from Figshare and how to run the project, restoring all the packages from the renv lock file, and also information about the contributors.Finally, I wanted to emphasize that I had to go over the same scripts multiple times, and sometimes doing a first cleanup of the code helped me realize that reorganizing the code in different way would actually be clearer, and so I ended up doing what felt like the same work twice. I think that that re-tidying––it shouldn’t be dismissed as being inefficient or not doing it right the first time, because in my case, I had to take a lot of time to just get my head around how the code was organized before I could make informed decisions about how to clean it up.So, I’ve talked about a lot of tools that I used in creating this reproducible pipeline, from Figshare to RStudio and RStudio Projects, GitHub for version control, Google Drawings in my case for creating this flowchart, and renv for organizing packages. And this might be overwhelming if you’ve never used these tools before and it feels like you have a lot of things to learn if you want to start implementing reproducible workflows. But I want to emphasize that there are smaller things that you can do to move in the right direction, even if you can’t jump right into using best practices from the get-go.For example, don’t be afraid to tell stories with your comments. I like to be very conversational; I like to say ‘Okay, now we’re going to do X’, ‘I noticed this about the output, and that causes me to make this decision about the model’ For example here, I wrote, ‘To make these calculations easier, I’m going to….’ do XYZ, and then I have some lines of code. Now, you’ll notice here that I only have about four lines of code, and a LOT of lines of comments, and not all of my scripts look like that. But I just want to get the point across that it’s really okay to write essays in your code and to have your code comments be informal, conversational and very descriptive.Something that Chelsea did in her raw code files that I found very helpful when I went through and organized them, was to keep track, in the comments, of package versions and decisions that were made in the analyses, and file paths. So for example, I already discussed how we had to use an older version of the package geomorph, and conveniently, Chelsea had recorded the version number of the older version that she was using, so it was much easier for me to then restore that version when I started using renv.You’ll notice that this script is far from being perfect; it’s still using absolute file paths, it hasn’t yet been edited to use the here package, but even without using all best practices in reproducibility, just having these introductory comments is really helpful.I want to conclude this talk by just emphasizing that we really need to teach workflow in graduate programs, undergraduate programs, whenever we teach coding. I would argue that, for biologists, workflow, organization, and reproducibility are some of the things that take up the greatest proportion of our research time. They are actually more valuable skills sometimes than the actual statistical analysis. They are also not intuitive. I think it can be easy, as a student, to assume that if you’re just an organized person, you will magically know how to organize your code. And then it’s easy to get frustrated when that doesn’t come naturally and when no one has really taught you what the best practices are. I think this resource, written by Jenny Bryan and Jim Hester, ‘What they forgot to teach you about R’, is a great example of this. This resource focuses on a lot of the workflow tactics that I’ve been talking about here, like a project-oriented workflow, and it’s titled ‘What they forgot to teach you about R’. And I think for many students, that’s exactly true. They do forget to teach you the workflow stuff, and that’s sometimes the most important part.Here’s a list of resources that I put together related to the various tools for reproducibility that I’ve talked about in this presentationAnd I would be happy to take any questions at the Q&A session right after this talk. Thank you very much.\n\nVideo\nFor the conference, I embedded captions in the video using iMovie, which was a pretty clunky process but was all I had access to at the time. There are some glitches and at one point I accidentally inserted the caption for a previous slide. On the whole, I hope the captions are better than nothing.\n\n\nResources\nThe resource links from the second to last slide didn’t translate well to this format, so here they are:\nRStudio interactive tutorials\nHappy Git with R (Jenny Bryan and Jim Hester)\nProject-oriented workflow with RStudio projects (Jenny Bryan)\nUsing RStudio projects\nUsing the here package\nHow to use renv\nKeeping a Paper Trail: Data Management Skills for Reproducible Science(Kate Laskowski)\nMake a README\nGet an embed link for a Google drawing so you can put it into e.g. a README\nUsing the `tree` command in the terminal to make a file tree\nThe document outline in RStudio\nHeaders and comments in RStudio (Y. Wendy Hyunh)\nWhat they forgot to teach you about R (Jenny Bryan and Jim Hester)\nFinally, you can download the video and the annotated slides from OSF here.\n\n\n\n",
    "preview": "projects/2021-07-13-retroactivelyReproducible/slideImages/0001.jpg",
    "last_modified": "2021-10-14T17:07:13-07:00",
    "input_file": {}
  },
  {
    "path": "projects/2021-05-13-greenT/",
    "title": "greenT: Exploring grapheme-color synesthesia",
    "description": "For my whole life, I've associated colors with letters and numbers. This is called grapheme-color synesthesia. For my second major project in Shiny, I built an app to help me explain synesthesia to friends, and to learn more about the experiences of other synesthetes.",
    "author": [
      {
        "name": "Kaija Gahm",
        "url": {}
      }
    ],
    "date": "2021-05-13",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: The digits 0-9, according to my brain\n\n\n\nI have what’s known as grapheme-color synesthesia. I experience letters and numbers as having colors associated with them. I don’t literally see colors floating in the air, but I’ve consistently associated a color with each letter and number for most of my life.\nWhen I tell my friends about my synesthesia, they want to know what color their name is. I wanted a way to quickly represent any word or words in the colors I see it in. I did a bit of googling to see if anyone had come up with a synesthesia simulator.\nThe closest thing I found was Bernadette Sheridan’s website synesthesia.me, which did exactly what I wanted to do, but only for Bernadette’s own colors! Cool, but not useful to me or to any other synesthetes (like my brother) who might want to show me their own colors.\nSo, I built this app. The source code for the app is here.\nFor a guided tour of the parts of the app, see this blog post\nTo read an explanation of the code used in the app, see this blog post\nThis was my second major Shiny project, after the YGDP Dashboard.\nHere’s the app, embedded:\n\n\nIf you have questions about this work, please feel free to get in touch. If you want to suggest an improvement or change to the app, or to report a bug or file a pull request, head over to the github page for the project.\nTo read more, make sure to check out my blog posts about this app. Part 1, Part 2\n\n\n\n",
    "preview": "projects/2021-05-13-greenT/numbers.png",
    "last_modified": "2021-10-27T16:50:01-07:00",
    "input_file": {},
    "preview_width": 1500,
    "preview_height": 750
  },
  {
    "path": "projects/2021-02-05-ygdp-dashboard/",
    "title": "YGDP Dashboard",
    "description": "From June through December 2020, I taught myself Shiny and ended up creating a pretty complicated interactive dashboard for exploring dialect variation across the US. Here's a bit about my experience using Shiny, as well as the app itself for you to play around with.",
    "author": [
      {
        "name": "Kaija Gahm",
        "url": {}
      }
    ],
    "date": "2021-02-05",
    "categories": [],
    "contents": "\nA map showing interpolated ratings data for the sentence “Here’s you some money.” A rating of 1 is “totally unacceptable sentence, even in casual conversation”, while 5 is “totally acceptable sentence.”Studying language across the US\nThe Yale Grammatical Diversity Project (YGDP) has been collecting survey data about syntax diversity in U.S. English for over five years.\nYou can read about the YGDP’s work here, but in a nutshell:\nWe put out surveys online to learn about people’s dialects across the United States\nWe ask survey participants to judge whether test sentences, such as “Here’s you a piece of pizza”, seem acceptable in casual conversation.\nWe’re not interested in “proper” or “correct” English–we want to know how people actually talk in real life across the country.\n(If you want to learn about the survey and data analysis methods in great detail, check out the comprehensive mapbook that we published earlier this year.)\nIn the past, there has been a lot of research into regional language diversity, but a lot of it has focused on lexical (words, vocabulary) diversity. A great example of that is the New York Times dialect quiz, which asks questions like “What do you call it when rain falls while the sun is shining?”, with answers ranging from “sunshower” to “the wolf is giving birth”.\nThe YGDP focuses more on syntactic (“grammatical”; related to syntax) diversity. So, they want to know how people put sentences together, not necessarily which words they use.\nThe Scots Syntax Atlas has done some great work along these lines in Scotland. The YGDP’s methods are a little different, but they’re asking the same types of questions about grammatical variation.\nI’m actually not a linguist, so I’m not going to explain the research in detail. To learn more about the YGDP’s research, you can check out their website. Head over to the grammatical phenomena pages to learn more about constructions like “All the further”, “Done my homework”, and “Come with”.\nData work\nIn 2019, I started working with the YGDP to pull together and organize their survey data. One of our primary goals was to make our findings easily accessible and explorable for anyone who might be interested.\nI had heard about R Shiny, but I had never created a Shiny app. In the spring of 2020, I talked to Jim Wood, one of the YGDP’s supervisors, about the possibility of developing a Shiny app to display the YGDP’s findings in a colorful, interactive way. Jim was excited about the idea, even though I had been very clear that I’d be starting absolutely from scratch and learning Shiny along the way.\nFrom June through December 2020, I dove in headfirst. I created a couple simple Shiny apps as practice, but then I set about developing a pretty complicated Shiny dashboard. I’ve always found that the best way to learn a new tool is to plunge in and use it, learning as you go. Learning Shiny was the ultimate baptism by fire. I think I started trying to create hierarchical selectInputs by about day 2, when I was still far from understanding the fundamentals of Shiny’s inputs and outputs. Next came the dashboard layout, which I achieved using shinydashboard and eventually shinydashboardPlus. I learned to insert a map using leaflet, another package I had never dabbled in.\n\n\n\nFigure 1: Hierarchical selectInputs: the choices in the ‘Sentence 1’ menu depend on the selection in ‘Survey’.\n\n\n\n\n\n\nFigure 2: A map made with the leaflet package\n\n\n\nThe dashboard is still evolving, but here is the current version. I’m immensely proud of how far I’ve come with Shiny, and I’m really excited about how this dashboard will allow the YGDP, and the general public, to explore the linguistic survey data in great detail.\n\n\nIf you have questions about this work, please feel free to get in touch. If you want to suggest an improvement or change to the dashboard, or to report a bug or file a pull request, head over to the github page for the project. I’ll be leaving the project shortly, so I’m not sure how actively the dashboard will be maintained, but suggestions are certainly welcome.\n\n\n\n",
    "preview": "projects/2021-02-05-ygdp-dashboard/hexMap.png",
    "last_modified": "2021-10-27T16:50:01-07:00",
    "input_file": {},
    "preview_width": 1434,
    "preview_height": 810
  },
  {
    "path": "projects/2021-01-29-tadpoles/",
    "title": "The Tadpole Olympics",
    "description": "For my B.S. thesis project at Yale, I measured how fast wood frog tadpoles swim in response to a simulated predator attack, and how that swimming speed relates to their developmental rate. It turns out that developing fast comes with a performance cost, and that tradeoff might help to explain some of the patterns we've observed in wood frogs' developmental rates in the past.",
    "author": [
      {
        "name": "Kaija Gahm",
        "url": {}
      }
    ],
    "date": "2021-01-29",
    "categories": [],
    "contents": "\nIntroduction\nFor my senior (B.S.) thesis in E&EB at Yale, I studied a tradeoff between growth rate and swimming performance in wood frog tadpoles.\nWhat does that mean? Basically, my collaborator Andis and I raised tadpoles in the lab under warm and cold conditions. Since frogs are cold-blooded, the warm tadpoles grew faster than the cold tadpoles.\nOn the one hand, growing rapidly is good for animals like wood frogs, who need to escape from predators and compete for mating opportunities. But when we stuck our tadpoles into an arena and tested how fast they swam, we found that the tadpoles pay a cost for that fast growth. The fast-growing (warm) tadpoles didn’t perform as well in their swimming trials as the slow-growing (cold) tadpoles.\nThis kind of tradeoff exists in other animals too, but we tested several populations of tadpoles and found that the effect was really consistent, no matter which population the tadpoles came from.\nWhat determines how fast a tadpole grows?\nWhy is this important? Well, our findings might help to explain a pattern that my lab has been wondering about for a while, called “countergradient variation”. Here’s how it works. We know that growing fast is helpful to tadpoles for a lot of reasons: they might have better mating or survival success as adults (though we don’t know this for sure); they might get too big for aquatic predators to eat while they’re still tadpoles; they can be sure to leave their ephemeral ponds before the water dries up in the summer; and they can get a head start on terrestrial life, perhaps outcompeting slower-growing tadpoles.\nTwo factors can help frogs grow fast: 1) environmental factors, like the temperature of the water they live in, and 2) genetic factors: that is, their genes can predispose them to “intrinsically” fast growth, independent of their environment.\nLet’s say we have two ponds in an imaginary forest, called “Fire Pond” and “Ice Pond” because one has really warm water and the other has really cold water.\nEnvironmental factors\nWe know that the tadpoles living in Fire Pond will grow faster than the tadpoles living in Ice Pond, since frogs are cold-blooded and their growth is pretty heavily influenced by the temperature of the water around them. Warmer water -> faster growth! This is the relationship that we made use of to manipulate our frogs’ developmental rates in the lab.\nGenetic factors\nFire Pond and Ice Pond are pretty far apart, and wood frogs tend to return to the same ponds where they grew up to breed. So, the frog populations in Fire and Ice can evolve roughly independently of each other.\nSo, if fast growth is unequivocally beneficial, then we might expect that both the Fire and Ice populations would evolve toward faster intrinsic growth and development. Put another way: natural selection would favor tadpoles that had genes for fast growth over those who grew more slowly, independent of the surrounding water temperature. We would expect to see this evolutionary trend in both ponds. Tadpoles from both Fire and Ice would evolve fast intrinsic growth rates, such that the Ice tadpoles will grow fast despite the cold water, and the Fire tadpoles will grow EXTRA FAST from the combined effects of genetics and warm water.\nBut this pattern is not what researchers, including the Skelly lab, have observed! When other studies have taken tadpoles from Fire and Ice and reared them at the same temperature (so, removing the effects of the different pond temperatures), they find that tadpoles from Fire grow more slowly than tadpoles from Ice. So, for some reason, those Fire frogs aren’t evolving to grow super fast intrinsically, even though doing so would let them have an edge over the chilly little Ice frogs.\nPutting it together\nThe pattern that I’ve described above is called “countergradient variation” because the frogs’ intrinsic (genetic) growth rates run in the opposite direction (counter-gradient) as their environmental circumstances.\nFor a while, we’ve wondered why we see this pattern. Why don’t the Fire tadpoles make the most of what seems like an advantage: their warm water? The countergradient pattern suggests that there must be a tradeoff, something that makes growing EXTRA FAST not quite so advantageous after all.\nThat’s where my study comes in. It turns out, growing fast comes with a cost in burst swimming speed! If you’re a tadpole, you might get bigger faster, but if you also swim more slowly than your slower-growing peers, you’re at risk of getting gobbled up by a predator. If that happens, all that growing would be for nothing.\nPaper\nMy collaborators and I published this work, and if you want to read more, you can download the paper. But I hope my description is a little easier to get through than the paper itself.\nIf you want a more detailed summary of the paper, with reference to each of its figures, Andis did a great job explaining it in his blog post.\nTalk\nIf you want to learn more about my work and would prefer to see a video of a talk I gave, aimed at a more general audience than the published paper, you can watch it below. This talk was given as part of the 2020 end-of-year E&EB Senior Symposium, which I organized as a remote event due to the COVID-19 pandemic.\nAcknowledgements and reflections\nThis work was made possible with the tremendous support of the Skelly Lab in the Yale School of the Environment. Andis Arietta, in particular, was a great mentor and collaborator. You should check out his research on his website and follow him on Twitter.\nThanks to Kirby Broderick and Simon Stump for help with the MATLAB code I wrote to analyze all my tadpole videos. Thanks to Joaquin Bellomio for help ground-truthing videos, and to Adriana Rubinstein and David Skelly for assistance in the lab.\nFinally, I want to recognize the privilege that allowed me to publish my research in 2020. Apart from summer fellowships, Yale doesn’t pay undergrads for research hours beyond course credit. I was able to spend a lot of extra hours in the lab during my senior year, hours that were not an option for a lot of my fellow students because they had to prioritize fulfilling their student income contributions (SIC) or working to support their families. Yale needs to abolish the SIC (SUN at Yale is doing great work toward this end) and pay undergraduate researchers to help even out these opportunities.\nWhen the COVID-19 pandemic hit, I was able to return to a calm and supportive home environment, where I had lots of time to work on preparing this manuscript for publication. Many of my friends had their thesis work cut short, and they had far more pressing things on their minds than writing and publishing papers. Across the scientific community, some academics are publishing more under lockdowns, while others (disproportionately women, people of color, those caring for children, etc.–aka people who were already at a disadvantage before this pandemic made things worse) have less time, not more, to devote to their work (see this and this, although this calls things into question. I don’t have good data for disparities by race and family status, and if/when I find papers that support/refute my intuition above, I’ll change my view accordingly!).\nI hope that in the coming years, we will see academia recognize that traditional metrics of success, like publication numbers and grant awards, are far from equitable, especially in the wake of this troubled year.\nThank you for reading, and if you have any questions about my work, please feel free to reach out!\n\n\n\n",
    "preview": "projects/2021-01-29-tadpoles/tadpole.png",
    "last_modified": "2022-03-10T11:37:04-08:00",
    "input_file": "tadpoles.knit.md",
    "preview_width": 1421,
    "preview_height": 575
  }
]
